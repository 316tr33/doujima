#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Codexæ¤œè¨¼: æ±æµ·é“è‹±èªç‰ˆ Phase 2
ç¿»è¨³ã®å®Œå…¨æ€§ã¨å“è³ªã‚’ç¢ºèª
"""

import re
from pathlib import Path

en_html = Path('../Tokaido/en/stations.html').read_text(encoding='utf-8')

print('=' * 80)
print('æ±æµ·é“è‹±èªç‰ˆ Phase 2 è©³ç´°æ¤œè¨¼ï¼ˆCodexï¼‰')
print('=' * 80)

all_ok = True
errors = []

# 1. æ—¥æœ¬èªæ–‡å­—ã®é©åˆ‡ãªé™¤å»ç¢ºèªï¼ˆç¿»è¨³å¯¾è±¡ã®ã¿ï¼‰
print('\nã€1. ç¿»è¨³å¯¾è±¡ã®æ—¥æœ¬èªé™¤å»ç¢ºèªã€‘')
# h3, station-description, station-highlightsã®ã¿ãƒã‚§ãƒƒã‚¯ï¼ˆä½æ‰€ãƒ»é§…åã¯é™¤å¤–ï¼‰
stations_content = re.search(r'<div class="stations-grid">(.*?)</div>\s*</div>\s*</section>', en_html, re.DOTALL)
if stations_content:
    content = stations_content.group(1)

    # ç¿»è¨³å¯¾è±¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º
    h3_texts = re.findall(r'<h3>([^<]+)</h3>', content)
    desc_texts = re.findall(r'<p class="station-description">\s*(.+?)\s*</p>', content, re.DOTALL)
    highlight_texts = re.findall(r'<div class="station-highlights">(.*?)</div>', content, re.DOTALL)

    japanese_found = False

    # h3ã«æ—¥æœ¬èªãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    ja_h3 = [h for h in h3_texts if re.search(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]', h)]
    if ja_h3:
        print(f'âœ— h3ã‚¿ã‚°ã«æ—¥æœ¬èª: {len(ja_h3)}ç®‡æ‰€')
        japanese_found = True

    # èª¬æ˜æ–‡ã«æ—¥æœ¬èªãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    ja_desc = [d for d in desc_texts if re.search(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]', d)]
    if ja_desc:
        print(f'âœ— èª¬æ˜æ–‡ã«æ—¥æœ¬èª: {len(ja_desc)}ç®‡æ‰€')
        japanese_found = True

    # ãƒã‚¤ãƒ©ã‚¤ãƒˆã«æ—¥æœ¬èªãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    ja_highlights = []
    for highlight in highlight_texts:
        spans = re.findall(r'<span>([^<]+)</span>', highlight)
        for span in spans:
            if re.search(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]', span):
                ja_highlights.append(span)

    if ja_highlights:
        print(f'âœ— ãƒã‚¤ãƒ©ã‚¤ãƒˆã«æ—¥æœ¬èª: {len(ja_highlights)}ç®‡æ‰€')
        japanese_found = True

    if not japanese_found:
        print('âœ“ ç¿»è¨³å¯¾è±¡ï¼ˆh3ã€èª¬æ˜æ–‡ã€ãƒã‚¤ãƒ©ã‚¤ãƒˆï¼‰ã®æ—¥æœ¬èªå®Œå…¨é™¤å»')
        print('  â€»ä½æ‰€ãƒ»é§…åã¯æ—¥æœ¬èªè¡¨è¨˜ã‚’ç¶­æŒï¼ˆæ„å›³çš„ï¼‰')
    else:
        all_ok = False
        errors.append('ç¿»è¨³å¯¾è±¡ã«æ—¥æœ¬èªæ®‹å­˜')
else:
    print('âœ— stations-gridã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
    all_ok = False
    errors.append('stations-gridä¸åœ¨')

# 2. å®¿å ´åã®è‹±èªè¡¨è¨˜ç¢ºèª
print('\nã€2. å®¿å ´åã®è‹±èªè¡¨è¨˜ã€‘')
h3_tags = re.findall(r'<h3>([^<]+)</h3>', en_html)
japanese_h3 = [h3 for h3 in h3_tags if re.search(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]', h3)]

if len(h3_tags) == 55 and len(japanese_h3) == 0:
    print(f'âœ“ 55ç®‡æ‰€ã™ã¹ã¦è‹±èªè¡¨è¨˜')
else:
    print(f'âœ— åˆè¨ˆ{len(h3_tags)}ç®‡æ‰€ã€æ—¥æœ¬èª{len(japanese_h3)}ç®‡æ‰€')
    for h3 in japanese_h3[:5]:
        print(f'  æ®‹å­˜: ã€Œ{h3}ã€')
    all_ok = False
    errors.append('å®¿å ´åã«æ—¥æœ¬èªæ®‹å­˜')

# 3. station-readingã®å®Œå…¨å‰Šé™¤ç¢ºèª
print('\nã€3. station-readingå‰Šé™¤ç¢ºèªã€‘')
reading_divs = len(re.findall(r'<div class="station-reading">', en_html))
if reading_divs == 0:
    print('âœ“ station-readingå®Œå…¨å‰Šé™¤')
else:
    print(f'âœ— {reading_divs}ç®‡æ‰€ã®station-readingãŒæ®‹å­˜')
    all_ok = False
    errors.append(f'station-readingæ®‹å­˜: {reading_divs}ç®‡æ‰€')

# 4. èª¬æ˜æ–‡ã®è‹±èªåŒ–ç¢ºèª
print('\nã€4. èª¬æ˜æ–‡ã®è‹±èªåŒ–ã€‘')
descriptions = re.findall(r'<p class="station-description">\s*(.+?)\s*</p>', en_html, re.DOTALL)
japanese_desc = [desc for desc in descriptions if re.search(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]', desc)]

if len(descriptions) == 55 and len(japanese_desc) == 0:
    print(f'âœ“ 55ç®‡æ‰€ã™ã¹ã¦è‹±èªåŒ–å®Œäº†')
else:
    print(f'âœ— åˆè¨ˆ{len(descriptions)}ç®‡æ‰€ã€æ—¥æœ¬èª{len(japanese_desc)}ç®‡æ‰€')
    for desc in japanese_desc[:3]:
        print(f'  æ®‹å­˜: ã€Œ{desc[:50]}...ã€')
    all_ok = False
    errors.append('èª¬æ˜æ–‡ã«æ—¥æœ¬èªæ®‹å­˜')

# 5. ãƒã‚¤ãƒ©ã‚¤ãƒˆã®è‹±èªåŒ–ç¢ºèª
print('\nã€5. ãƒã‚¤ãƒ©ã‚¤ãƒˆã®è‹±èªåŒ–ã€‘')
highlights = re.findall(r'<div class="station-highlights">(.*?)</div>', en_html, re.DOTALL)
total_spans = 0
japanese_spans = 0
japanese_examples = []

for highlight in highlights:
    spans = re.findall(r'<span>([^<]+)</span>', highlight)
    for span_text in spans:
        total_spans += 1
        if re.search(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]', span_text):
            japanese_spans += 1
            if len(japanese_examples) < 5:
                japanese_examples.append(span_text)

if japanese_spans == 0:
    print(f'âœ“ {total_spans}ç®‡æ‰€ã™ã¹ã¦è‹±èªåŒ–å®Œäº†')
else:
    print(f'âœ— åˆè¨ˆ{total_spans}ç®‡æ‰€ä¸­ã€{japanese_spans}ç®‡æ‰€ã«æ—¥æœ¬èªæ®‹å­˜')
    for example in japanese_examples:
        print(f'  æ®‹å­˜: ã€Œ{example}ã€')
    all_ok = False
    errors.append(f'ãƒã‚¤ãƒ©ã‚¤ãƒˆã«æ—¥æœ¬èªæ®‹å­˜: {japanese_spans}ç®‡æ‰€')

# 6. è©³ç´°æƒ…å ±ãƒ©ãƒ™ãƒ«ã®è‹±èªåŒ–ç¢ºèª
print('\nã€6. è©³ç´°æƒ…å ±ãƒ©ãƒ™ãƒ«ã®è‹±èªåŒ–ã€‘')
# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å†…ã®detail-itemã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ•ãƒƒã‚¿ãƒ¼é™¤å¤–ï¼‰
main_only = en_html.split('<footer')[0] if '<footer' in en_html else en_html
detail_items = re.findall(r'<div class="detail-item">.*?<span>([^<]+)</span>', main_only, re.DOTALL)

japanese_labels = ['è¦‹å­¦æ™‚é–“ï¼š', 'æœ€å¯„ã‚Šé§…ï¼š', 'ä½æ‰€ï¼š', 'æ‰€åœ¨åœ°ï¼š', 'äº¤é€šï¼š', 'ã‚¢ã‚¯ã‚»ã‚¹ï¼š', 'å–¶æ¥­æ™‚é–“ï¼š', 'å…¥å ´æ–™ï¼š']
japanese_detail_count = sum(main_only.count(label) for label in japanese_labels)

if japanese_detail_count == 0:
    print(f'âœ“ æ—¥æœ¬èªãƒ©ãƒ™ãƒ«å®Œå…¨é™¤å»ï¼ˆ{len(detail_items)}ç®‡æ‰€ç¢ºèªï¼‰')
else:
    print(f'âœ— {japanese_detail_count}ç®‡æ‰€ã«æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ãŒæ®‹å­˜')
    for label in japanese_labels:
        count = main_only.count(label)
        if count > 0:
            print(f'  æ®‹å­˜: {label} ({count}ç®‡æ‰€)')
    all_ok = False
    errors.append(f'è©³ç´°ãƒ©ãƒ™ãƒ«ã«æ—¥æœ¬èªæ®‹å­˜: {japanese_detail_count}ç®‡æ‰€')

# 7. è‹±èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å“è³ªãƒã‚§ãƒƒã‚¯
print('\nã€7. è‹±èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ªãƒã‚§ãƒƒã‚¯ã€‘')
# åŸºæœ¬çš„ãªè‹±å˜èªãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
common_words = ['the', 'and', 'of', 'to', 'in', 'a', 'is', 'was']
word_found = sum(1 for word in common_words if word in en_html.lower())

if word_found >= 6:
    print(f'âœ“ è‹±èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç¢ºèªï¼ˆä¸€èˆ¬çš„ãªè‹±å˜èª{word_found}ç¨®é¡æ¤œå‡ºï¼‰')
else:
    print(f'âœ— è‹±èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä¸è¶³ï¼ˆ{word_found}ç¨®é¡ã®ã¿æ¤œå‡ºï¼‰')
    all_ok = False
    errors.append('è‹±èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä¸è¶³')

# 8. HTMLã‚¿ã‚°ãƒãƒ©ãƒ³ã‚¹ï¼ˆPhase 1ã‹ã‚‰ã®ç¶™ç¶šï¼‰
print('\nã€8. HTMLã‚¿ã‚°ãƒãƒ©ãƒ³ã‚¹ã€‘')
for tag in ['div', 'section', 'main', 'h3', 'p']:
    open_count = len(re.findall(rf'<{tag}[^>]*>', en_html))
    close_count = len(re.findall(rf'</{tag}>', en_html))

    if open_count == close_count:
        print(f'âœ“ <{tag}>: é–‹{open_count}/é–‰{close_count}')
    else:
        print(f'âœ— <{tag}>: é–‹{open_count}/é–‰{close_count}ï¼ˆä¸ä¸€è‡´ï¼‰')
        all_ok = False
        errors.append(f'<{tag}>ã‚¿ã‚°ä¸ä¸€è‡´')

# 9. ç”»åƒãƒ‘ã‚¹ç¢ºèªï¼ˆPhase 1ã‹ã‚‰ã®ç¶™ç¶šï¼‰
print('\nã€9. ç”»åƒãƒ‘ã‚¹ç¢ºèªã€‘')
image_paths = re.findall(r'<img[^>]+src="([^"]+)"', en_html)
wrong_paths = [path for path in image_paths if path.startswith('../images/')]
correct_paths = [path for path in image_paths if path.startswith('../../images/')]

if len(wrong_paths) == 0 and len(correct_paths) > 0:
    print(f'âœ“ ç”»åƒãƒ‘ã‚¹æ­£å¸¸ï¼ˆ../../images/ ã‚’ {len(correct_paths)}ç®‡æ‰€ä½¿ç”¨ï¼‰')
else:
    print(f'âœ— ä¸æ­£ãªç”»åƒãƒ‘ã‚¹: {len(wrong_paths)}ç®‡æ‰€')
    if wrong_paths:
        print(f'  ä¾‹: {wrong_paths[0]}')
    all_ok = False
    errors.append(f'ç”»åƒãƒ‘ã‚¹ä¸æ­£: {len(wrong_paths)}ç®‡æ‰€')

# 10. data-numberé€£ç•ªç¢ºèªï¼ˆPhase 1ã‹ã‚‰ã®ç¶™ç¶šï¼‰
print('\nã€10. data-numberé€£ç•ªç¢ºèªã€‘')
data_numbers = sorted(set([int(m) for m in re.findall(r'data-number="(\d+)"', en_html)]))
expected = list(range(55))

if data_numbers == expected:
    print(f'âœ“ 0-54ã®é€£ç•ªï¼ˆ55ç®‡æ‰€ï¼‰')
else:
    missing = set(expected) - set(data_numbers)
    extra = set(data_numbers) - set(expected)
    print(f'âœ— data-numberç•°å¸¸')
    if missing:
        print(f'  æ¬ æ: {sorted(missing)}')
    if extra:
        print(f'  ä½™åˆ†: {sorted(extra)}')
    all_ok = False
    errors.append('data-numberä¸ä¸€è‡´')

# æœ€çµ‚çµæœ
print('\n' + '=' * 80)
if all_ok:
    print('ğŸ‰ Codexæ¤œè¨¼ Phase 2: 100ç‚¹æº€ç‚¹ï¼')
    print('ğŸ“Š è‹±èªç‰ˆã®ç¿»è¨³ãŒå®Œç’§ã«å®Œäº†ã—ã¦ã„ã¾ã™')
    print('\nã€æ¤œè¨¼åˆæ ¼é …ç›®ã€‘')
    print('  âœ“ ç¿»è¨³å¯¾è±¡ã®æ—¥æœ¬èª: å®Œå…¨é™¤å»ï¼ˆh3ã€èª¬æ˜æ–‡ã€ãƒã‚¤ãƒ©ã‚¤ãƒˆï¼‰')
    print('  âœ“ å®¿å ´å: 55ç®‡æ‰€ã™ã¹ã¦è‹±èªåŒ–')
    print('  âœ“ station-reading: å®Œå…¨å‰Šé™¤')
    print('  âœ“ èª¬æ˜æ–‡: 55ç®‡æ‰€ã™ã¹ã¦è‹±èªåŒ–')
    print('  âœ“ ãƒã‚¤ãƒ©ã‚¤ãƒˆ: ã™ã¹ã¦è‹±èªåŒ–')
    print('  âœ“ è©³ç´°ãƒ©ãƒ™ãƒ«: ã™ã¹ã¦è‹±èªåŒ–')
    print('  âœ“ è‹±èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„: å“è³ªè‰¯å¥½')
    print('  âœ“ HTMLã‚¿ã‚°ãƒãƒ©ãƒ³ã‚¹: å®Œå…¨')
    print('  âœ“ ç”»åƒãƒ‘ã‚¹: æ­£å¸¸ï¼ˆ../../images/ï¼‰')
    print('  âœ“ data-number: 0-54é€£ç•ª')
    print('\nã€æ³¨è¨˜ã€‘')
    print('  - ä½æ‰€ãƒ»é§…åã¯æ—¥æœ¬èªè¡¨è¨˜ã‚’ç¶­æŒï¼ˆå®Ÿéš›ã®åœ°åã¨ã—ã¦æ­£ç¢ºæ€§å„ªå…ˆï¼‰')
    print('  - data-featureså±æ€§ã¯è‹±èªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åŒ–å®Œäº†')
    print('  - ç”»åƒaltå±æ€§ã¯è‹±èªåŒ–å®Œäº†')
    print('=' * 80)
    exit(0)
else:
    print(f'âŒ Codexæ¤œè¨¼ Phase 2: {len(errors)}ä»¶ã®ã‚¨ãƒ©ãƒ¼')
    print('\nã€ã‚¨ãƒ©ãƒ¼ä¸€è¦§ã€‘')
    for i, error in enumerate(errors, 1):
        print(f'{i}. {error}')
    print('=' * 80)
    exit(1)
